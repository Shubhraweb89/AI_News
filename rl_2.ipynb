{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fb53595",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\CIS_Project\\venv\\Lib\\site-packages\\transformers\\models\\bart\\configuration_bart.py:177: UserWarning: Please make sure the config includes `forced_bos_token_id=0` in future versions. The config can simply be saved and uploaded again to be fixed.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"Shubhraweb89/bart_samsum_model\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Shubhraweb89/bart_samsum_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90e1a12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(article_text):\n",
    "    input_ids = tokenizer(article_text, return_tensors=\"pt\", truncation=True, max_length=1024).input_ids\n",
    "    output_ids = model.generate(\n",
    "        input_ids,\n",
    "        do_sample=True,\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "        max_length=128,\n",
    "        num_return_sequences=1\n",
    "    )\n",
    "    summary = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    return summary, output_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ca16d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_feedback(summary):\n",
    "    print(\"Generated Summary:\\n\", summary)\n",
    "    feedback = int(input(\"Like = 1, Dislike = 0: \"))\n",
    "    return feedback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59d51e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def compute_log_probs(input_ids, output_ids):\n",
    "    outputs = model(input_ids=input_ids, decoder_input_ids=output_ids[:, :-1])\n",
    "    logits = outputs.logits[:, :-1, :]  # skip the last token\n",
    "    target_ids = output_ids[:, 1:]      # shift for teacher forcing\n",
    "\n",
    "    # Cross-entropy manually\n",
    "    log_probs = F.cross_entropy(\n",
    "        logits.reshape(-1, logits.size(-1)),\n",
    "        target_ids.reshape(-1),\n",
    "        ignore_index=tokenizer.pad_token_id,\n",
    "        reduction=\"mean\"\n",
    "    )\n",
    "    return -log_probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb2d5b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\CIS_Project\\venv\\Lib\\site-packages\\transformers\\generation\\utils.py:1737: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed in v5. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Summary:\n",
      "  \"Chinese blessing scams\" occur worldwide. Chinese blessing scams have been reported worldwide for 25 years. They are targeted Asian women usually Asian women's wealth.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.58.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 → Reward: 1.0 → Loss: 1.1465\n",
      "Generated Summary:\n",
      "  scam where an elderly lady is convinced family member is cursed and should have her wealth blessed. Authorities are investigating it worldwide.\n",
      "Step 1 → Reward: -1.0 → Loss: -1.4784\n",
      "Generated Summary:\n",
      " Erin Patterson has been found guilty of three counts of murder and attempted murder. 12-member jury reached the verdict after around six days of deliberation following a 10-week trial in Morwell, an hour's drive from the dining room in Leongatha, Victoria, where the lethal lunch was served in July 2023.\n",
      "Step 2 → Reward: -1.0 → Loss: -0.3888\n",
      "Generated Summary:\n",
      "  mushrooms baked in a Beef Wellington lunch were served to a group of three in Morwell, Victoria. Erin Patterson was convicted of three counts of murder and the attempted murder of the lone survivor. \n",
      "Step 3 → Reward: 1.0 → Loss: 0.7419\n",
      "Generated Summary:\n",
      "  poison and fabricated a cancer claim in order to get her lunch invitation.\n",
      "Step 4 → Reward: -1.0 → Loss: -1.3624\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=5e-6)\n",
    "\n",
    "def compute_log_probs(input_ids, output_ids):\n",
    "    # Shift decoder input ids and labels\n",
    "    decoder_input_ids = output_ids[:, :-1]\n",
    "    labels = output_ids[:, 1:]\n",
    "\n",
    "    outputs = model(input_ids=input_ids, decoder_input_ids=decoder_input_ids)\n",
    "    logits = outputs.logits\n",
    "\n",
    "    # Safety check: truncate logits to match labels\n",
    "    logits = logits[:, :labels.size(1), :]\n",
    "\n",
    "    loss = F.cross_entropy(\n",
    "        logits.reshape(-1, logits.size(-1)),\n",
    "        labels.reshape(-1),\n",
    "        ignore_index=tokenizer.pad_token_id,\n",
    "        reduction='mean'\n",
    "    )\n",
    "    return -loss  # return log-prob\n",
    "\n",
    "# Your loop\n",
    "for step in range(5):\n",
    "    article = input(\"Paste article text: \")\n",
    "    \n",
    "    summary, output_ids = generate_summary(article)\n",
    "    print(\"Generated Summary:\\n\", summary)\n",
    "    feedback = int(input(\"Like = 1, Dislike = 0: \"))\n",
    "\n",
    "    input_ids = tokenizer(article, return_tensors=\"pt\", truncation=True, max_length=1024).input_ids\n",
    "\n",
    "    # Ensure everything is on the same device\n",
    "    input_ids = input_ids.to(model.device)\n",
    "    output_ids = output_ids.to(model.device)\n",
    "\n",
    "    log_prob = compute_log_probs(input_ids, output_ids)\n",
    "    reward = 1.0 if feedback == 1 else -1.0\n",
    "\n",
    "    loss = -reward * log_prob\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    print(f\"Step {step} → Reward: {reward} → Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d81b84c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\CIS_Project\\venv\\Lib\\site-packages\\transformers\\modeling_utils.py:3685: UserWarning: Moving the following attributes in the config to the generation config: {'forced_bos_token_id': 0}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('bart_summarizer_with_rl\\\\tokenizer_config.json',\n",
       " 'bart_summarizer_with_rl\\\\special_tokens_map.json',\n",
       " 'bart_summarizer_with_rl\\\\vocab.json',\n",
       " 'bart_summarizer_with_rl\\\\merges.txt',\n",
       " 'bart_summarizer_with_rl\\\\added_tokens.json',\n",
       " 'bart_summarizer_with_rl\\\\tokenizer.json')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path = \"bart_summarizer_with_rl\"\n",
    "\n",
    "model.save_pretrained(save_path)\n",
    "tokenizer.save_pretrained(save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab85e62f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in e:\\cis_project\\venv\\lib\\site-packages (0.33.1)\n",
      "Requirement already satisfied: filelock in e:\\cis_project\\venv\\lib\\site-packages (from huggingface_hub) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in e:\\cis_project\\venv\\lib\\site-packages (from huggingface_hub) (2025.5.1)\n",
      "Requirement already satisfied: packaging>=20.9 in e:\\cis_project\\venv\\lib\\site-packages (from huggingface_hub) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in e:\\cis_project\\venv\\lib\\site-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in e:\\cis_project\\venv\\lib\\site-packages (from huggingface_hub) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in e:\\cis_project\\venv\\lib\\site-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in e:\\cis_project\\venv\\lib\\site-packages (from huggingface_hub) (4.14.0)\n",
      "Requirement already satisfied: colorama in e:\\cis_project\\venv\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in e:\\cis_project\\venv\\lib\\site-packages (from requests->huggingface_hub) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\cis_project\\venv\\lib\\site-packages (from requests->huggingface_hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\cis_project\\venv\\lib\\site-packages (from requests->huggingface_hub) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\cis_project\\venv\\lib\\site-packages (from requests->huggingface_hub) (2025.6.15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install huggingface_hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db2b35b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in e:\\cis_project\\venv\\lib\\site-packages (4.53.0)\n",
      "Requirement already satisfied: filelock in e:\\cis_project\\venv\\lib\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in e:\\cis_project\\venv\\lib\\site-packages (from transformers) (0.33.1)\n",
      "Requirement already satisfied: numpy>=1.17 in e:\\cis_project\\venv\\lib\\site-packages (from transformers) (2.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\cis_project\\venv\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in e:\\cis_project\\venv\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in e:\\cis_project\\venv\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in e:\\cis_project\\venv\\lib\\site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in e:\\cis_project\\venv\\lib\\site-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in e:\\cis_project\\venv\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in e:\\cis_project\\venv\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in e:\\cis_project\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.5.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in e:\\cis_project\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
      "Requirement already satisfied: colorama in e:\\cis_project\\venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in e:\\cis_project\\venv\\lib\\site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\cis_project\\venv\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\cis_project\\venv\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\cis_project\\venv\\lib\\site-packages (from requests->transformers) (2025.6.15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39bf65a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli login\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14f7709",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"bart_summarizer_with_rl\")\n",
    "tokenizer.save_pretrained(\"bart_summarizer_with_rl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af2b3859",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"E:\\CIS_Project\\venv\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py\", line 409, in hf_raise_for_status\n",
      "    response.raise_for_status()\n",
      "  File \"E:\\CIS_Project\\venv\\Lib\\site-packages\\requests\\models.py\", line 1026, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/api/repos/create\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"e:\\CIS_Project\\venv\\Scripts\\huggingface-cli.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"E:\\CIS_Project\\venv\\Lib\\site-packages\\huggingface_hub\\commands\\huggingface_cli.py\", line 59, in main\n",
      "    service.run()\n",
      "  File \"E:\\CIS_Project\\venv\\Lib\\site-packages\\huggingface_hub\\commands\\repo.py\", line 137, in run\n",
      "    repo_url = self._api.create_repo(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\CIS_Project\\venv\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 114, in _inner_fn\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\CIS_Project\\venv\\Lib\\site-packages\\huggingface_hub\\hf_api.py\", line 3746, in create_repo\n",
      "    hf_raise_for_status(r)\n",
      "  File \"E:\\CIS_Project\\venv\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py\", line 482, in hf_raise_for_status\n",
      "    raise _format(HfHubHTTPError, str(e), response) from e\n",
      "huggingface_hub.errors.HfHubHTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/api/repos/create (Request ID: Root=1-686ead03-31d31ddd23fe3cce519925df;24824310-f650-48ab-9b4e-fa722b28844a)\n",
      "\n",
      "Invalid username or password.\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli repo create my-news-summarizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a833545",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
